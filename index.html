<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Reality Aware Networks Portal</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="" />
<meta name="author" content="http://webthemez.com" />
<!-- css -->
<link href="css/bootstrap.min.css" rel="stylesheet" />
<link href="css/fancybox/jquery.fancybox.css" rel="stylesheet">
<link href="css/jcarousel.css" rel="stylesheet" />
<link href="css/flexslider.css" rel="stylesheet" />
<link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
<link href="css/style.css" rel="stylesheet" />
 
<!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

</head>
<body>
<div id="wrapper" class="home-page">
	<!-- start header -->
	<header>
        <div class="navbar navbar-default navbar-static-top">
            <div class="container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
            </div>
        </div>
	</header>
	<!-- end header -->
	<section id="banner">
	 
	<!-- Slider -->
	<div id="main-slider" class="flexslider">
		<ul class="slides">
			<li>
				<video autoplay loop muted playsinline>
					<source src="vid/router.mp4" type="video/mp4">
					Your browser does not support the video tag.
				</video>
				<div class="flex-caption">
					<h3>Reality-Aware Networks</h3> 
					<p>Rutgers University</p>
					<p>Stony Brook University</p> 
					<p>Georgia State University</p> 
				</div>
			</li>
		</ul>
	</div>
	<!-- end slider -->

	<!-- Slider
        <div id="main-slider" class="flexslider">
            <ul class="slides">
              <li>
                <img src="img/slides/2.jpg" alt="" />
                <div class="flex-caption">
                    <h3>Reality-Aware Networks</h3> 
					<p>Rutgers University</p>
					<p>Old Dominion University</p> 
					<p>Stony Brook University</p> 
					<p>Georgia State University</p> 
                </div>
              </li>
            </ul>
        </div>
	end slider -->
 
	</section>
	<section class="callaction">
	<div class="container">
		<div class="row">
			<div class="col-lg-22">
				<div class="alignleft"><h1 class="alignleft">Synopsis</h1>This project seeks to improve the robustness of wireless sensing and networking technologies through a reality-aware wireless architecture that blends networking and sensing. Robust perception and high-bandwidth networking benefit innovations across a diverse spectrum of high-impact areas including mixed-reality, robotics, and automated vehicles. For example, the use of such techniques to enhance driver assistance systems or automated vehicles has the potential to save numerous lives. In addition to disseminating results through scholarly publication, the project will engage the wireless and automotive industry to facilitate the technology transfer. The project also includes a set of integrated education and broadening participation activities to engage and retain students from underrepresented groups through internship programs, educational and outreach activities at each participating institution.

					<br><br>As wireless sensing and networking technologies make significant strides in today’s world, applications such as automated driving or augmented reality are increasingly involving rich sensing of the environment with unprecedented network requirements. Existing approaches that strictly separate the network stack and the perception component face challenges in providing robust perception and high-bandwidth networking. To address this, this project develops and studies a reality-aware wireless architecture that blends networking and sensing components, rather than isolating them. This approach exploits sensor information and scene geometry to provide improved and more predictable wireless network performance. It also uses information received over the network to aid perception functions such as object recognition and point correspondence. The team first explores the design space of network architectures for blending perception and communication by designing low-energy tags and visual signaling strategies. The team then develops Simultaneous Localization and Mapping(SLAM) algorithms that blends conventional strategies with network information to enhance robustness. It also designs geometric matching techniques to enhance object association in images with network information. At the network and link layers, the system will exploit knowledge about physical obstacles and the surrounding geometry obtained from camera views and other sensors to provide more predictable and seamless high-bandwidth coverage. The outcomes from the thrusts are integrated into a Reality-Aware Network(RAN) architecture that exploits information about the environment gathered via sensors. The architecture is implemented and evaluated in indoor and outdoor experiments, culminating in a validation on the Platform for Advanced Wireless Research (PAWR) COSMOS testbed.</div>
				
			</div>
		</div>
	</div>
	</section>
	

	</section>
	<section class="callaction">
	<div class="container">
		<div class="row">
			<div class="col-lg-22">
				<div class="alignleft"><h1 class="alignleft">Personnel</h1>

					<div class="alignleft"><h2 class="alignleft">Principal Investigators</h2>
						<ul>
							<li><a href="https://www.ece.rutgers.edu/kristin-dana">Dr. Kristin Dana, Professor in the Dept. of ECE at Rutgers University</a></li>
							<li><a href="http://www.winlab.rutgers.edu/~gruteser/">Dr. Marco Gruteser, Research Scientist at Google (Prev. Professor in the Dept. of ECE at Rutgers University)</a></li>
							<li><a href="http://www.winlab.rutgers.edu/~narayan/index.html">Dr. Narayan Mandayam, Professor in the Dept. of ECE at Rutgers University</a></li>
							<li><a href="http://shubhamjain.net">Dr. Shubham Jain, Assistant Professor in the Dept. of CS, Stony Brook University</a></li>
							<li><a href="http://ashwinashok.com">Dr. Ashwin Ashok, Assistant Professor in the Dept. of CS, Georgia State University</a></li>
						  </ul>
						
					<div class="alignleft"><h2 class="alignleft"> Graduate Students </h2>
						<ul>
							<li>Faith Johnson, Rutgers University</li>
							<li>Ryan Meegan, Rutgers University</li>
							<li>Vincenzo DiMatteo, Rutgers University</li>
							<li>Abrar Alali, Old Dominion University</li>
							<li>MD Rashed Rahman, Georgia State University</li>
							<li>Bo (Bryan) Cao, Stony Brook University</li>
						  </ul>
					<div class="alignleft"><h2 class="alignleft"> Undergraduate Students </h2>
						<ul>
							<li>Adam D'Souza, Rutgers University</li>
						</ul>

					<div class="alignleft"><h2 class="alignleft"> Former Students </h2>
						<ul>
						<li>Hansi Liu, Samsung, (Ph.D. Rutgers University 2022)</li>
						<li>Mohamed Ibrahim, Postdoc at Carnegie Mellon University (Ph.D. Rutgers University 2021)</li>
						<li>AbdulHasseb Ahmed, Microsoft (M.S. in CS from Georgia State University 2021)</li>
						<li>Hongyu Li, Google (Ph.D. in ECE from Rutgers University 2021)</li>
						<li>Sethuraman TV, Research Assistant IIT Madras, India (Former Undergraduate student, VIT, Chennai 2020)</li>
						</ul>

			</div>
		</div>
	</div>
	</section>

	<section id="content">
	
	
	<div class="container">

	</div>
	</section>
	
		<section class="aboutUs">
	<div class="container">
		<div class="row">
			<div class="col-md-12">
				<div class="aligncenter"><h2 class="aligncenter">Publications</h2></div>
				<ul>
				  <li>
					<p>Meegan, Nicholas, Hansi Liu, Bryan Cao, Abrar Alali, Kristin Dana, Marco Gruteser, Shubham Jain, and Ashwin Ashok. <a href=https://arxiv.org/abs/2210.05513>"ViFiCon: Vision and Wireless Association Via Self-Supervised Contrastive Learning."</a> arXiv preprint arXiv:2210.05513 (2022).</p>
				  </li>
				  <li>
					<p>Johnson, Faith, Bryan Bo Cao, Kristin Dana, Shubham Jain, and Ashwin Ashok. <a href=https://arxiv.org/abs/2402.12498>"Feudal Networks for Visual Navigation."</a> arXiv preprint arXiv:2402.12498 (2024).</p>
				  </li>
				  <li>
					<p>Cao, Bryan Bo, Abrar Alali, Hansi Liu, Nicholas Meegan, Marco Gruteser, Kristin Dana, Ashwin Ashok, and Shubham Jain. <a href=https://ieeexplore.ieee.org/abstract/document/9918171>"Vitag: Online wifi fine time measurements aided vision-motion identity association in multi-person environments."</a> In 2022 19th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON), pp. 19-27. IEEE, 2022.</p>
				  </li>
				  <li>
					<p>Ibrahim, Mohamed, Ali Rostami, Bo Yu, Hansi Liu, Minitha Jawahar, Viet Nguyen, Marco Gruteser, Fan Bai, and Richard Howard. <a href="https://github.com/ashwinashok/realityawarenetworks/blob/master/files/Wi-Go_%20Accurate%20and%20Scalable%20Vehicle%20Positioning%20using%20WiFi%20Fine%20Timing%20Measurement.pdf">“Wi-Go: accurate and scalable vehicle positioning using WiFi fine timing measurement”</a> In Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services, 312–324. June 2020.</p>
				  </li>
				  <li>
					<p>Hansi Liu, Abrar Alali, Mohamed Ibrahim, Hongyu Li, Marco Gruteser, Shubham Jain, Kristin Dana, Ashwin Ashok, Bin Cheng, Hongsheng Lu. <a href="http://winlab.rutgers.edu/~hansiiii/papers/mobisys21/Mobisys21_demo__Camera_Ready_.pdf">“Demo: Lost and Found! Associating Target Persons in Camera Surveillance Footage with Smartphone Identifiers.”</a> In The 19th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys ’21), June 24-July 2, 2021, Virtual, WI, USA.</p>
				
					<p><a href="https://drive.google.com/drive/folders/1PLy5vKYdacEanCqgKIehxY_guWesTMPo?usp=sharing">Demo Slides Demo Video 1 Demo Video 2</a></p>
				  </li>
				  <li>
					<p>Hansi Liu, Abrar Alali, Mohamed Ibrahim, Bryan Bo Cao, Nicholas Meegan, Hongyu Li, Marco Gruteser, Shubham Jain, Kristin Dana, Ashwin Ashok, Bin Cheng, Hongsheng Lu.
				<a href="https://winlab.rutgers.edu/~hansiiii/papers/ViFi_Paper___IPSN_2022__Camera_Ready_.pdf">“Vi-Fi: Associating Moving Subjects across Vision and Wireless Sensors”</a>. In The International Conference on Information Processing in Sensor Networks(IPSN 2022) , Milan, Italy, May 4 2022.</p>
				
					<p><a href="https://github.com/vifi2021/Vi-Fi">Code</a></p>
				  </li>
				  <li>
					<p>Bryan Bo Cao, Hansi Liu, Abrar Alali, Nicholas Meegan, Shubham Jain, Ashwin Ashok, Marco Gruteser, Kristin Dana. <a href="https://drive.google.com/file/d/1bNIvgbp-KBZbdAYT7Xj5UoQmglQZTw67/view?usp=sharing">“ViTag: Online WiFi Fine Time Measurements Aided Vision-Motion Identity Association in Multi-person Environments”</a> In the 19th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON 2022), Virtual, September 20, 2022.</p>
				
					<p><a href="https://docs.google.com/presentation/d/1GKwpigRg_Oxold2e3ZxjXOIp7bOsj5YQPPaLt9aee_o/edit?usp=sharing">Slides</a> <a href="https://github.com/bryanbocao/vitag">Code</a></p>
				  </li>
				  <li>
					<p>Bryan Bo Cao, Hansi Liu, Abrar Alali, Nicholas Meegan, Shubham Jain, Ashwin Ashok, Marco Gruteser, Kristin Dana. <a href="https://drive.google.com/file/d/1ynsZ-DH8GBDef4GiDlniP7jTlfxdkLDL/view?usp=sharing">“Demo: Tagging Vision with Smartphone Identities by Vision2Phone Translation”</a> (<strong><a href="https://secon2022.ieee-secon.org/program/">Best Demonstration Award</a></strong>) In the 19th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON 2022), Virtual, September 20, 2022.</p>
				
					<p><a href="https://docs.google.com/presentation/d/1r-PGJpESl7-ixbDCqIrKMlH3BOrCD239RWsX97KVIW4/edit?usp=sharing">Slides</a></p>
				  </li>
				  <li>
					<p>Bryan Bo Cao, Abrar Alali, Hansi Liu, Nicholas Meegan, Marco Gruteser, Kristin Dana, Ashwin Ashok, Shubham Jain, <a href="https://dl.acm.org/doi/abs/10.1145/3615984.3616503">“ViFiT: Reconstructing Vision Trajectories from IMU and Wi-Fi Fine Time Measurements”</a>, 2023 The 29th Annual International Conference On Mobile Computing And Networking (MobiCom), 3rd ACM MobiCom Workshop on Integrated Sensing and Communication Systems for IoT (ISACom), Spain, 2-6 October 2023. <a href="https://arxiv.org/pdf/2310.03140.pdf">arXiv</a></p>
				
					<p><a href="https://docs.google.com/presentation/d/1ICOyCk__dErtpvLKCEz73hzmRii7fVKOVxHsDE7Smrk/edit?usp=sharing">Slides</a> <a href="https://github.com/bryanbocao/vifit">Code</a> <a href="https://drive.google.com/file/d/1A-MvqHgU9udUhXe864p2FQblAMS2q3uO/view?usp=drive_link">Presentation</a></p>
				  </li>
				</ul>

				<br/>
			</div>
		</div>
		<div class="row">

			<div class="container">
				<div class="row">
					<div class="col-md-12">
						<div class="aligncenter"><h2 class="aligncenter">Datasets</h2></div>
					<ul>
						<li>
							<p>Johnson, Faith, Bryan Bo Cao, Kristin Dana, Shubham Jain, and Ashwin Ashok. <a href=https://arxiv.org/abs/2402.14281>"A Landmark-Aware Visual Navigation Dataset."</a> arXiv preprint arXiv:2402.14281 (2024).</p>
						</li>
						<li>
							<p>Please see our <a href="https://sites.google.com/winlab.rutgers.edu/vi-fidataset">Vi-Fi Dataset (Raw Data)</a>, <a href="https://drive.google.com/drive/folders/1fZmWWQoNIhkd7Fk9HhziCPotaCppHOLt?usp=sharing">Synchronized Data (Google Drive)</a>, <a href="https://1drv.ms/f/s!AqkVlEZgdjnYoG6k1wMfgyrvbmSU">Synchronized Data (OneDrive)</a> &amp; <a href="https://github.com/bryanbocao/vitag/blob/main/DATA.md">DATA.md</a></p>
						</li>
					</ul>
			
		
		</div
	
	</div>
	</section>
	<section id="clients">
        <div class="container">
            	<div class="row">
			<div class="col-md-12">
				<div class="aligncenter"><h2 class="aligncenter">Educational Outreach and Activities</h2></div>
				<br/>

				<ul>
					<li>
						Faith Johnson gave a seminar in the Microsoft Future AI Leaders at the University of Maryland
						<p><a href="https://www.youtube.com/watch?v=cGQtYk70WFs">Recording of Talk</a> <a  href=https://robotics.umd.edu/event/19163/microsoft-future-leaders-in-robotics-and-ai-seminar-series-faith-johnson> Abstract</a></p>

					</li>
					<li>
						<p>Participation in Rutgers Day (Additonal information/ link needed)</p>
					</li>
						<li>
						  <p><strong>PI Gruteser</strong> (Google / Rutgers University, New Brunswick, USA) was on the SIGMOBILE’s Executive Committee. The conference hosts events to broaden participation. In partnership with the N2Women group, the conference hosted a mentoring dinner meeting at MobiCom’19.</p>
						</li>
						<li>
						  <p><strong>PI Dana</strong> supervised undergraduate students in capstone design including an all-female group that won the departments third place capstone prize Project S20-56: 2020Vision, Team members: Roshni Shah, Shruthi Sureshkrishnan, and Nithyasree Natarajan. Their project automatically recognized human outdoor activity observed by a Ring video doorbell using deep learning.</p>
						</li>
						<li>
						  <p><strong>PI Jain</strong> piloted the Mentorship Program at ACM MobiCom 2019. The goal of the program is to prepare young researchers (students and post-docs) to have the most productive experience at the conference. <strong>Jain</strong> (along with the co-organizer) matched mentees with mentors based on interest and facilitated meetings at the conference. The mentees were also prepared starting a week before the conference by giving them daily challenges. The response to the program was positive. A second version of the program, to be conducted at ACM MobiCom 2020, in a virtual format is currently underway. <strong>Jain</strong> was also one of the organizers of the annual Great Computer Challenge, which
					  is a coding competition for high school students from the Hampton Roads area, at ODU in Spring 2020. This year witnessed more female participants than previous year due to
					  increased efforts in publicity at school level.</p>
						</li>
						<li>
						  <p><strong>PI Ashok</strong> has been involving Women undergraduate students in learning activities related to the scope of this project. In particular, <strong>Ashok</strong> has been conducting discussion sessions on VLC, Python programming and Wireless communication concepts, as a part of the training exercises in the bi-weekly meetings with the <a href="https://www.girlswhocodecollegeloopatgeorgiastateuniversity.com/grow-robotics">girlswhocode GROW club (founded by PI Ashok)</a>.</p>
						</li>
				</ul>
			</div>
		</div>

	<div class="col-md-12">
		<div class="aligncenter"><h2 class="aligncenter">Funding</h2></div>
		<p>This work has been supported by the National Science Foundation (NSF) under the grant of CNS Core: Medium: Collaborative: Reality Aware Networks (CNS-1901355, 1910170, 1901133)</p>
	<span class="site-footer-owner"><a href="https://github.com/ashwinashok/realityawarenetworks">realityawarenetworks</a> is maintained by <a href="https://github.com/ashwinashok">Vincenzo DiMatteo</a> and <a href=https://github.com/RNGmeg> Ryan Meegan </a></span>
  
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
</div>

</section>

        

<a href="#" class="scrollup"><i class="fa fa-angle-up active"></i></a>
<!-- javascript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="js/jquery.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.fancybox.pack.js"></script>
<script src="js/jquery.fancybox-media.js"></script> 
<script src="js/portfolio/jquery.quicksand.js"></script>
<script src="js/portfolio/setting.js"></script>
<script src="js/jquery.flexslider.js"></script>
<script src="js/animate.js"></script>
<script src="js/custom.js"></script>
<script src="js/owl-carousel/owl.carousel.js"></script>
</body>
</html>